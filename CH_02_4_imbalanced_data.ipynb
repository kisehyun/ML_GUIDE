{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Data\n",
    "***\n",
    "\n",
    "이번 챕터에서는 비대칭 데이터(Imbalanced Data) 해결 방법에 대해 알아보도록 하겠습니다. 비대칭 데이터는 일반적으로 분류(classification) 문제 해결에서 예측 대상 클래스들이 불규칙할 경우 문제를 일으킵니다.\n",
    "\n",
    "예를 들어 1만명의 환자 데이터로 암 발병 여부를 예측한다고 했을 때 암에 걸리지 않은 환자가 9900명일 때를 가정해봅시다. 평가지표는 정확도(accuracy)일 때 모델을 따로 구성하지 않고 10,000명의 사람이 모두 암에 걸리지 않았ek고 예측하면 정확도는 무려 99%를 달성하게 됩니다. 즉 예측의 정확도(accuracy)는 높아지지만 재현율(recall : 실제 양성을 양성이라고 옳게 예측할 확률)이 매우 낮을 것입니다.\n",
    "\n",
    "하지만 이런 식으로 환자의 암 발병 여부를 예측할 때 실제 암에 걸린 사람을 암에 걸리지 않았다고 예측하면 암 환자의 상태는 더 위독해질 것입니다.\n",
    "\n",
    "이렇듯 비대칭 데이터 문제를 해결할 때에는 데이터의 샘플링과 올바른 평가지표 사용이 중요하다고 볼 수 있습니다.\n",
    "***\n",
    "\n",
    "데이터 샘플링의 방식은 아래와 같이 크게 두 가지가 존재합니다.\n",
    "\n",
    "1. Over Sampling = 데이터의 수가 소수인 클래스의 데이터를 추가적으로 더 만들어낸다.\n",
    "\n",
    "\n",
    "2. Under Sampling = 데이터의 수가 다수인 클래스의 데이터를 일부만 사용한다.\n",
    "\n",
    "일반적으로 Over Sampling이 성능이 더 좋은 경우가 많아 자주 사용됩니다.\n",
    "***\n",
    "비대칭 데이터 문제 해결시 올바른 평가지표로는 아래와 같은 기준들이 권장되고 있습니다.\n",
    "\n",
    "1. Confusion Matrix\n",
    "\n",
    "2. Precision\n",
    "\n",
    "3. Recall\n",
    "\n",
    "4. F1 Score\n",
    "\n",
    "5. ROC AUC\n",
    "\n",
    "***\n",
    "각종 방법들을 사용할 때는 학습 데이터에만 샘플링을 적용하여야 합니다. 실제 우리가 풀어야할 테스트 데이터에는 샘플링을 적용하면 올바른 테스트가 진행되지 못하기 때문입니다.\n",
    "\n",
    "***\n",
    "\n",
    "먼저 Over Sampling 기법들에 대해 알아보도록 하겠습니다. \n",
    "\n",
    "대표적인 Over Sampling 기법인 SMOTE와 RandomOverSampler을 사용해 비교해보도록 하죠.\n",
    "\n",
    "\n",
    "데이터는 kaggle의 신용카드 사기 검출 데이터를 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import *\n",
    "from imblearn.under_sampling import *\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/KI/Vacation/2019summer/python_machinelearning_guide/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 클래스의 개수 차이가 압도적으로 나는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 1:-1]\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state = 1219)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling의 효과만 알아보기 위해 별도의 변수 전처리는 진행하지 않도록 하겠습니다.\n",
    "\n",
    "우선 baseline 모델 구성을 위해서 LightGBM으로 성능을 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(random_state = 1219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(random_state=1219)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_class = lgbm.predict(X_test)\n",
    "baseline_prob = lgbm.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_acc = round(accuracy_score(y_test, baseline_class), 4)\n",
    "base_precision = round(precision_score(y_test, baseline_class), 4)\n",
    "base_recall = round(recall_score(y_test, baseline_class), 4)\n",
    "base_f1 = round(f1_score(y_test, baseline_class), 4)\n",
    "base_roc_auc = round(roc_auc_score(y_test, baseline_prob), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 모델의 정확도는 99.68%\n",
      "baseline 모델의 정밀도는 20.810000000000002%\n",
      "baseline 모델의 재현율는 42.86%\n",
      "baseline 모델의 f1 score는 28.02%\n",
      "baseline 모델의 roc auc socre는 54.03%\n"
     ]
    }
   ],
   "source": [
    "print(f'baseline 모델의 정확도는 {base_acc * 100}%')\n",
    "print(f'baseline 모델의 정밀도는 {base_precision * 100}%')\n",
    "print(f'baseline 모델의 재현율는 {base_recall * 100}%')\n",
    "print(f'baseline 모델의 f1 score는 {base_f1 * 100}%')\n",
    "print(f'baseline 모델의 roc auc socre는 {base_roc_auc * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline 모델의 경우 정확도를 제외한 모든 지표에서 낮은 성능을 보이고 있습니다.\n",
    "***\n",
    "\n",
    "이제 SMOTE 기법을 적용해 학습 및 평가를 해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state = 1220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smote, y_smote = smote.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 데이터의 shape = (284807, 29)\n",
      "SMOTE 적용 후 데이터의 shape = (454874, 29)\n"
     ]
    }
   ],
   "source": [
    "print(f'원본 데이터의 shape = {X.shape}')\n",
    "print(f'SMOTE 적용 후 데이터의 shape = {X_smote.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE 적용 후 데이터가 2배로 늘어난 것을 알 수 있습니다.\n",
    "\n",
    "이번에는 예측값의 클래스 분포를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 후 클래스 분포 :\n",
      "1    227437\n",
      "0    227437\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'SMOTE 적용 후 클래스 분포 :\\n{pd.Series(y_smote).value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE 적용 후 예측값의 클래스가 1대1로 동일해진 것을 알 수 있습니다. 이제 생성된 데이터로 학습한 후 성능을 평가해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = LGBMClassifier(random_state = 1219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(random_state=1219)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(X_smote, y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_class = lgbm.predict(X_test)\n",
    "smote_prob = lgbm.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOTE_acc = round(accuracy_score(y_test, smote_class), 4)\n",
    "SMOTE_precision = round(precision_score(y_test, smote_class), 4)\n",
    "SMOTE_recall = round(recall_score(y_test, smote_class), 4)\n",
    "SMOTE_f1 = round(f1_score(y_test, smote_class), 4)\n",
    "SMOTE_roc_auc = round(roc_auc_score(y_test, smote_prob), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 모델의 정확도는 99.86%\n",
      "SMOTE 모델의 정밀도는 52.21%\n",
      "SMOTE 모델의 재현율는 84.52%\n",
      "SMOTE 모델의 f1 score는 64.55%\n",
      "SMOTE 모델의 roc auc socre는 93.08999999999999%\n"
     ]
    }
   ],
   "source": [
    "print(f'SMOTE 모델의 정확도는 {SMOTE_acc * 100}%')\n",
    "print(f'SMOTE 모델의 정밀도는 {SMOTE_precision * 100}%')\n",
    "print(f'SMOTE 모델의 재현율는 {SMOTE_recall * 100}%')\n",
    "print(f'SMOTE 모델의 f1 score는 {SMOTE_f1 * 100}%')\n",
    "print(f'SMOTE 모델의 roc auc socre는 {SMOTE_roc_auc * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE 적용 후 모든 평가 지표에서 성능이 개선된 것을 알 수 있습니다. \n",
    "\n",
    "이번에는 RandomOverSampler를 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state = 1220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ros, y_ros = ros.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomOverSampler 적용 후 클래스 분포 :\n",
      "1    227437\n",
      "0    227437\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'RandomOverSampler 적용 후 클래스 분포 :\\n{pd.Series(y_ros).value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE와 동일하게 데이터가 2배로 늘어난 것을 확인하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(random_state=1219)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(X_ros, y_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros_class = lgbm.predict(X_test)\n",
    "ros_prob = lgbm.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros_acc = round(accuracy_score(y_test, ros_class), 4)\n",
    "ros_precision = round(precision_score(y_test, ros_class), 4)\n",
    "ros_recall = round(recall_score(y_test, ros_class), 4)\n",
    "ros_f1 = round(f1_score(y_test, ros_class), 4)\n",
    "ros_roc_auc = round(roc_auc_score(y_test, ros_prob), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomOverSampler모델의 정확도는 99.95%\n",
      "RandomOverSampler모델의 정밀도는 81.17999999999999%\n",
      "RandomOverSampler모델의 재현율는 82.14%\n",
      "RandomOverSampler모델의 f1 score는 81.66%\n",
      "RandomOverSampler모델의 roc auc socre는 95.89999999999999%\n"
     ]
    }
   ],
   "source": [
    "print(f'RandomOverSampler모델의 정확도는 {ros_acc * 100}%')\n",
    "print(f'RandomOverSampler모델의 정밀도는 {ros_precision * 100}%')\n",
    "print(f'RandomOverSampler모델의 재현율는 {ros_recall * 100}%')\n",
    "print(f'RandomOverSampler모델의 f1 score는 {ros_f1 * 100}%')\n",
    "print(f'RandomOverSampler모델의 roc auc socre는 {ros_roc_auc * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMOTE 보다는 재현율이 2%가량 낮지만 나머지 지표에서는 모두 성능이 더 좋은 것을 알 수 있습니다.\n",
    "\n",
    "해당 문제에서는 Over Sampling 적용이 좋은 성능을 보였지만 모든 문제에서 해당되는 것이 아니기 때문에 여러 요소를 고려한 후 결정을 해야합니다.\n",
    "***\n",
    "\n",
    "이번에는 Under Sampling 기법을 활용해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak = AllKNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ak, y_ak = ak.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AllKNN 적용 후 클래스 분포 :\n",
      "0    227268\n",
      "1       408\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'AllKNN 적용 후 클래스 분포 :\\n{pd.Series(y_ak).value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래스가 0인 데이터의 수는 60000개 가량 줄었고 클래스가 1인 데이터도 약간 줄어든 것을 알 수 있습니다. 감소 비율은 클래스가 0인 데이터에서 더 높았지만 애초에 수가 매우 적었던 클래스 1데이터도 감소했기 때문에 어느 정도 데이터의 손실은 있다고 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(random_state=1219)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(X_ak, y_ak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak_class = lgbm.predict(X_test)\n",
    "ak_prob = lgbm.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ak_acc = round(accuracy_score(y_test, ak_class), 4)\n",
    "ak_precision = round(precision_score(y_test, ak_class), 4)\n",
    "ak_recall = round(recall_score(y_test, ak_class), 4)\n",
    "ak_f1 = round(f1_score(y_test, ak_class), 4)\n",
    "ak_roc_auc = round(roc_auc_score(y_test, ak_prob), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AllKNN모델의 정확도는 99.95%\n",
      "AllKNN모델의 정밀도는 81.17999999999999%\n",
      "AllKNN모델의 재현율는 82.14%\n",
      "AllKNN모델의 f1 score는 81.66%\n",
      "AllKNN모델의 roc auc socre는 95.89999999999999%\n"
     ]
    }
   ],
   "source": [
    "print(f'AllKNN모델의 정확도는 {ak_acc * 100}%')\n",
    "print(f'AllKNN모델의 정밀도는 {ak_precision * 100}%')\n",
    "print(f'AllKNN모델의 재현율는 {ak_recall * 100}%')\n",
    "print(f'AllKNN모델의 f1 score는 {ak_f1 * 100}%')\n",
    "print(f'AllKNN모델의 roc auc socre는 {ak_roc_auc * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 InstanceHardnessThreshold 기법을 적용해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "iht = InstanceHardnessThreshold(random_state = 1220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iht, y_iht = iht.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InstanceHardnessThreshold 적용 후 클래스 분포 :\n",
      "0    227268\n",
      "1       408\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'InstanceHardnessThreshold 적용 후 클래스 분포 :\\n{pd.Series(y_ak).value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AllKNN처럼 두 클래스에서 모두 데이터가 일정 비율 감소한 것을 확인했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(random_state=1219)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm.fit(X_iht, y_iht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "iht_class = lgbm.predict(X_test)\n",
    "iht_prob = lgbm.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "iht_acc = round(accuracy_score(y_test, iht_class), 4)\n",
    "iht_precision = round(precision_score(y_test, iht_class), 4)\n",
    "iht_recall = round(recall_score(y_test, iht_class), 4)\n",
    "iht_f1 = round(f1_score(y_test, iht_class), 4)\n",
    "iht_roc_auc = round(roc_auc_score(y_test, iht_prob), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InstanceHardnessThreshold모델의 정확도는 99.6%\n",
      "InstanceHardnessThreshold모델의 정밀도는 21.29%\n",
      "InstanceHardnessThreshold모델의 재현율는 63.1%\n",
      "InstanceHardnessThreshold모델의 f1 score는 31.830000000000002%\n",
      "InstanceHardnessThreshold모델의 roc auc socre는 75.92999999999999%\n"
     ]
    }
   ],
   "source": [
    "print(f'InstanceHardnessThreshold모델의 정확도는 {iht_acc * 100}%')\n",
    "print(f'InstanceHardnessThreshold모델의 정밀도는 {iht_precision * 100}%')\n",
    "print(f'InstanceHardnessThreshold모델의 재현율는 {iht_recall * 100}%')\n",
    "print(f'InstanceHardnessThreshold모델의 f1 score는 {iht_f1 * 100}%')\n",
    "print(f'InstanceHardnessThreshold모델의 roc auc socre는 {iht_roc_auc * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 기법들과 달리 눈에 띌만큼 성능이 개선되지 않은 것을 확인하였습니다.\n",
    "***\n",
    "이외에도 imblearn에는 combine, ensemble 패키지가 추가적으로 더 있습니다. 이번 챕터에서는 다루지 않았지만 관심이 있으신 분들은 공식문서를 참고해서 공부하시면 될 것 같습니다.\n",
    "***\n",
    "이번 챕터에서는 불균형 데이터 문제를 해결할 수 있는 여러가지 기법들에 대해서 알아보았습니다. 모든 ML 문제가 그렇듯이 정해진 해결 방법은 없습니다. 모든 방법을 시도해보고 수정해가면서 해당 문제를 가장 잘 해결할 수 있는 방법을 찾는 것이 가장 중요할 것입니다. \n",
    "\n",
    "다음 챕터에서는 스태킹(Stacking) 기법에 대해서 알아보도록 하겠습니다. 감사합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
